---
title: "CatData Final"
author: "Matthew Vanaman"
date: '`r format(Sys.Date(), "%m-%d-%Y")`'
monofont: Courier New
output:
  pdf_document: 
    latex_engine: xelatex
  word_document: default
header-includes: \usepackage{tikz,xcolor,listings, caption}
---
`r knitr::opts_knit$set(root.dir='..')`

```{r, include=FALSE}
library(ProjectTemplate); load.project()
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
options(scipen = 999, xtable.comment = FALSE)
knitr::opts_chunk$set(engine.path = "/anaconda3/bin/python")
np <- reticulate::import("numpy")
sympy <- reticulate::import_from_path("sympy", path = "/anaconda3/lib/python3.7/site-packages")
```

```{r, echo=FALSE}
pvalr <- function(pvals, sig.limit = .001, digits = 3, html = FALSE) {

  roundr <- function(x, digits = 1) {
    res <- sprintf(paste0('%.', digits, 'f'), x)
    zzz <- paste0('0.', paste(rep('0', digits), collapse = ''))
    res[res == paste0('-', zzz)] <- zzz
    res
  }

  sapply(pvals, function(x, sig.limit) {
    if (x < sig.limit)
      if (html)
        return(sprintf('&lt; %s', format(sig.limit))) else
          return(sprintf('< %s', format(sig.limit)))
    if (x > .1)
      return(roundr(x, digits = 2)) else
        return(roundr(x, digits = digits))
  }, sig.limit = sig.limit)
}
```

\captionsetup{justification=raggedright,singlelinecheck=false}

# 5.19

### (a)

$\text{logit} (\pi) = \alpha + \beta_1 M_1 + \beta_2 M_2 + \beta_3 M_3 + \beta_4 M_4 + \beta_5 M_5 + \beta_6 M_6$, with M = major, once for each level. When you want to assess the effect of a particular level of major, code that major (e.g. $M_3$) to 1 and the rest to zero.

### (b)

```{r, echo=FALSE}
dev <- pvalr(pchisq(21.7, df=6, lower.tail = FALSE))
```


The deviance goodness-of-fit test approximates the $\chi^2$ for GLMs with binomial responses and large numbers of successes and failures. Our model meets these criteria. The p-value for the deviance test is `r dev`, indicating that other possible predictors excluded from this model may not equal zero (i.e. bad fit).

### (c)

The rule of thumb for standardized residuals is that residuals with aboslute values above 2 or 3 are suspect. Most of the standardized residuals given are pretty small, with the exception of the first Major. This indicates that the model in (a) with Major as the only predictor may not have good fit because it excludes another important predictor (gender).

### (d)

Because the model in (a) excludes a predictor for gender, it assumes an equal probability of admission for males and females across majors. If this is true, the standardized residuals should be close to zero (they are normally distributed when the model holds). Because gender is a binary predictor in this case, we can expect the standardized residual for males to be identical to female, but with an opposite sign. In other words, whatever deviation from the expected probability there is for females, there is probability of equal magnitude in the opposite direction for males. The residual of -4.15 for males indicates that males have a lower-than-expected probability of admission, likely violating the assumption of equal probability for males and females within that major.

### (e)

First of all, this illustrates Simpson's paradox: failing to account for differences across majors leads to an effect in the opposite direction. When you condition on major females have 10% lower odds of admission, yet collapsing over major, females have 84% greater odds of admission. This *could* mean that females apply to the more competitive majors relatively more often, so are accepted less often than males after conditioning on major. So when you control for major, females fare worse because the majors they are applying to are more competitive. Males on the other hand, are applying to less competitive majors, meaning that when you average across majors of varying difficulty, it appears that males are doing worse. When you allow for the conditionality of major, males fare better because they apply in relatively higher numbers to the easier majors. This shows why it's important to keep track of whom applies to where when making group comparisons.

# 7.9

9 Table7.23referstoapplicantstograduateschoolattheUniversityofCalifornia, Berkeley for the fall 1973 session. Admissions decisions are presented by gender of applicant, for the six largest graduate departments. Denote the three variables by A = whether admitted, F = female, and M = major Fit loglinear model (AM, AF, MF).

a. Report the estimated AF conditional odds ratio, and compare it with the AF marginal odds ratio. Why are they so different?

b. Report $G^2$ and df values, and comment on the quality of ﬁt. Conduct a residual analysis. Describe the lack of ﬁt.

c. Deleting the data for major 1, re-ﬁt the model. Interpret.

d. Deleting the data for Department 1 and treating A as the response variable, ﬁt an equivalent logistic model for model (AM, AF, MF) in (c). Show how to use each model to obtain an odds ratio estimate of the effect of F on A, controlling for D.

### (a)

```{r, echo=FALSE, results="asis"}
berk_admin$major <- as.factor(berk_admin$major)
berk_admin$female <- as.factor(berk_admin$female)
berk_admin$admit <- as.factor(berk_admin$admit)
fit <- glm(count ~ admit + female + major + admit:major + admit:female + major:female, family=poisson, data=berk_admin)
print(xtable::xtable(summary(fit), caption = "Model", align = "lrrrr"), caption.placement = "top", latex.environments = "flushleft")
fitted <- as.data.frame(predict(fit, type = "response"))
berk_admin <- cbind(berk_admin,round(fitted,2))
```

To get the conditional odds ratio for AF (which is AG, except the gender variable is called F in this case), you exponentiate the admit:female coefficient: exp(-0.1084) = `r round(exp(-0.1084),2)`. \newpage

```{r, echo=FALSE, results="asis"}
Mno <- berk_admin[1:6,5]
Fno <- berk_admin[7:12,5]
Myes <- berk_admin[13:18,5]
Fyes <- berk_admin[19:24,5]
sum_Mno <- round(sum(berk_admin[1:6,5]),2)
sum_Fno <- round(sum(berk_admin[7:12,5]),2)
sum_Myes <- round(sum(berk_admin[13:18,5]),2)
sum_Fyes <- round(sum(berk_admin[19:24,5]),2)

margins <- as.data.frame(matrix(c(1,2,3,4,5,6, "", "Total",
                                  
                                  Myes, "", sum_Myes,
                                  
                                  Mno, "", sum_Mno,
                                  
                                  Fyes, "", sum_Fyes,
                                  
                                  Fno, "", sum_Fno),
                                
                                nrow=8, ncol=5))

names(margins) <- c("Major", "Myes", "Mno", "Fyes", "Fno")
print(xtable::xtable(margins, caption = "Fitted Values", align = "lrrrrr"), caption.placement = "top", include.rownames=FALSE, latex.environments = "flushleft")
# get marg odds

marg_OR <- round((sum_Fno * sum_Myes)/(sum_Fyes * sum_Mno),2)
```


To get the marginal odds, you can use use of the model fitted count values. In this case, we're ignoring the Major grouping. Using the totals of each column, with admission indicated by the subscrtipt, the calculation comes out to be 
$$\frac {\textrm{F}_{no} \times \textrm{M}_{yes}} {\textrm{F}_{yes} \times \textrm{M}_{no}},$$ $$= \frac {`r sum_Fno` \times `r sum_Myes`} {`r sum_Fyes` \times `r sum_Mno`},$$
$$= `r marg_OR`.$$
This turns out to be nearly identical to the marginal odds ratio of the raw counts.


## (b)

```{r, results="asis", echo=FALSE}
dev <- round(fit$deviance,2)
df <- fit$df.residual
p <- pvalr(pchisq(dev, df=5, lower.tail = FALSE))
SRs <- as.data.frame(resid(fit, type="pearson")/sqrt(1 - hatvalues(fit)))
colnames(SRs) <- "Std Res"
berk_admin <- cbind(berk_admin, SRs)
print(xtable::xtable(berk_admin[,c(2:4,6)], caption = "Predictors and Standardized Residuals", align = "rcccr"), caption.placement = "top", include.rownames=FALSE, latex.environments = "flushleft")
```


The deviance for this model is `r dev`, *df* = 5, $p$ = `r p`. Bad fit. 

As can be seen from the table above, the standardized residuals show that there doesn't seem to be much misfit about the admit and female predictors, but major, specifically at level 1, is consistently problematic. 

## (c)

```{r, echo=FALSE, results="asis"}
fit_drop <- glm(count ~ admit + female + major + admit:major + admit:female + major:female, family=poisson, subset = (major != 1), data=berk_admin)
print(xtable::xtable(summary(fit_drop), caption = "Model Sans Major 1", align = "lrrrr"), caption.placement = "top", latex.environments = "flushleft")

dev_drop <- round(fit_drop$deviance,2)
df_drop <- fit_drop$df.residual
p_drop <- pvalr(pchisq(dev_drop, df=5, lower.tail = FALSE))
```

The deviance for this new model is `r dev_drop`, *df* = `r df_drop`, $p$ = `r p_drop`. Fit has improved a lot. 

## (d)


```{r, echo=FALSE, results="asis"}
logit <- glm(admit ~ female + major + major:female, weights = count, family=binomial, subset = (major != 1), data=berk_admin)
print(xtable::xtable(summary(logit), caption = "Logit Model Sans Major 1", align = "lrrrr"), caption.placement = "top", latex.environments = "flushleft")

dev_drop <- round(fit_drop$deviance,2)
df_drop <- fit_drop$df.residual
p_drop <- pvalr(pchisq(dev_drop, df=5, lower.tail = FALSE))
logit_nogender <- glm(admit ~ major, weights = count, family=binomial, subset = (major != 1), data=berk_admin)

OR_logit <- round(exp(0.2200),2)
dev_comp <- round(logit_nogender$deviance - logit$deviance,2)
df_comp <- logit_nogender$df.residual - logit$df.residual 
p_comp <- pvalr(pchisq(dev_comp, df = df_comp, lower.tail = FALSE))
```

The equivalent logit model yields a conditional odds ratio between gender and admissions is exp(0.2200) = `r OR_logit`. Compare this to the OR from the previous model, which is exp(-0.0307) = `r round(exp(-0.0307),2)`. The logit model shows much less of an effect of gender on admissions than the poisson model. Given the negligibale effect of gender on admissions, it might be worth comparing a model with no gender terms. A deviance test between these models shows the the simpler model with no gender variable works just as well as the model with gender ($G^2$ = `r dev_comp`, $df$ = `r df_comp`, $p$ = `r p_comp`). Thus it is important to carefully consider model assumptions when choosing a test.

# 4.37

### (a)

This is true. To figure this out, find the $\textrm{log} (\hat \pi)$ for each coding scheme:
$$\textrm{log} (\hat \pi) = −2.06 + .87d − 2.40v.$$
Defendent white, victim black:
$$`r - 2.06 + .87*(0) - 2.40*(1)` = \textrm{log}(`r round(exp(- 2.06 + .87*(0) - 2.40*(1)),2)`) = −2.06 + .87(0) − 2.40(1).$$
Defendent black, victim white:
$$`r - 2.06 + .87*(1) - 2.40*(0)` = \textrm{log}(`r round(exp(- 2.06 + .87*(1) - 2.40*(0)),2)`) = −2.06 + .87(1) − 2.40(0).$$

Defendent black, victim black:
$$`r - 2.06 + .87*(0) - 2.40*(0)` = \textrm{log}(`r round(exp(- 2.06 + .87*(0) - 2.40*(0)),2)`) = −2.06 + .87(0) − 2.40(0).$$
Defendent white, victim white:
$$`r - 2.06 + .87*(1) - 2.40*(1)` = \textrm{log}(`r round(exp(- 2.06 + .87*(1) - 2.40*(1)),2)`) = −2.06 + .87(0) − 2.40(0).$$

### (b)

False. An OR of 1.15 would indicate that whites have 15% greater odds of the death penalty. There's no reason why changing the coding should flip the effect since the relative relationships among the variables remain the same no matter how they are coded. Only now your coefficient will be 1.15, so to get the odds for whites you take 1/1.15, which is 0.87.

### (c)

True. This is the definition of an interaction: there is no multiplicative effect of one variable on the other; the effect of one variable remains constant across all levels of the other variable. You could have also said that the estimated odds ratio between the death penalty out come and victim’s race is the same for each category of defendent's race.


### (d)

Nope. The intercept is on the log-odds scale.

### (e)

True. Victim and defendent variables would both be coded as zero, meaning that the expected count for when v = 0 and d = 0 is just the logit with no other terms in the exponent. In other words:
$$\dfrac {500 e^{\alpha + B_d d+ B_v v}} {(1 - e^{\alpha + B_d d+ B_v v})},$$
$$= \dfrac {500 e^{-2.06 + 0.87 (0) - 2.40(0)}} {(1 - e^{-2.06 + 0.87 (0) - 2.40(0)})},$$
$$= \dfrac {500 e^{-2.06}} {(1 - e^{-2.06})}.$$

