---
title: "CatData HW3"
author: "Matthew Vanaman"
date: "03/11/19"
monofont: Courier New
output:
  pdf_document:
    fig_caption: yes
    latex_engine: xelatex
  word_document: default
header-includes: \usepackage{tikz,xcolor,listings}
---
`r knitr::opts_knit$set(root.dir='..')`

```{r, include=FALSE}
library(ProjectTemplate); load.project()
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
options(scipen = 999)
knitr::opts_chunk$set(engine.path = "/anaconda3/bin/python")
np <- reticulate::import("numpy")
sympy <- reticulate::import_from_path("sympy", path = "/anaconda3/lib/python3.7/site-packages")
```

A2.21, A2.36. (3 points each)

A2.33 (5 points)

*All code and work are shown in the appendix.*

# 2.2

## (a)
**Answer:**\newline
Recoding this in a way that makes more sense to me. Will leave X and Y as they are:\newline

- $X (0 = \textrm {no disease}, 1 = \textrm {disease})$\newline
- $Y (0 = \textrm {negative}, 1 = \textrm {positive})$\newline
- $\textrm {Sensitivity} = \pi_1 = P(Y = 1|X = 1) = \textrm {probability positive diagnosis given disease}$\newline
- $\textrm {Specificity} = 1 - \pi_2 = 1 - P(Y = 1|X = 0) = \textrm {1 - probability positive diagnosis given no disease}$\newline 

After subtracting away the  probability of positive diagnosis given no disease, you are left with probability of negative diagnosis given no disease:\newline

$1 - P(Y = 1|X = 0) =  P(Y = 0|X = 0) = \textrm {probability negative diagnosis given no disease}$\newline

Likewise, the "noise" of the test is captured by 1 - specificity. A good test would want to show that 1 - specificity yields a large probability as an effective test will have a large probability of correctly screening patients that do not have the disease. \newline

## (b)
**Answer:**\newline
$P(X = 1|Y = 1) = \dfrac {P(Y = 1|X = 1)P(X = 1)} {P(Y = 1|X = 1)P(X = 1) + P(Y = 1|X = 0) P(X = 0)}$.\newline



**Work:**\newline
$$\dfrac {\pi_1 \gamma} {[ \pi_1 \gamma + \pi_2 (1 - \gamma) ]} = \dfrac {P(B|A)P(A)} {P(B)} = \textrm {Bayes' rule}$$.\newline

In the above equation, P(B) represents P(X=1), or the probability of having the disease. But this is an unknown value expressed as $\gamma$, we have to use a particular version of Bayes' rule that takes into account the conditional probabilities associated with P(B):\newline
$$P(A|B) = \dfrac {P(B|A)P(A)} {P(B|A)P(A) + P(B| \widetilde A) P(\widetilde A)}.$$\newline
Just replace with the problem's notation:
$$P(X = 1|Y = 1) = \dfrac {P(Y = 1|X = 1)P(X = 1)} {P(Y = 1|X = 1)P(X = 1) + P(Y = 1|X = 0) P(X = 0)}$$.\newline

## (c)
**Answer:**\newline
0.07\newline


**Work:**\newline

We need to solve for $P(X = 1 | Y = 1)$. Lay out the pieces:\newline

- $X (0 = \textrm {no disease}, 1 = \textrm {disease}$.\newline
- $P(X = 1) = 0.01$.\newline
- $Y (0 = \textrm {negative}, 1 = \textrm {positive}$.\newline
- $\textrm {Sensitivity} = \pi_1 = P(Y = 1|X = 1) = 0.86$.\newline
- $\textrm {Specificity} = 1 - \pi_2 = 1 - P(Y = 1|X = 0) = 0.88$\newline 
- If $1 - P(Y = 1|X = 0) = 0.88$, then $P(Y = 1|X = 0) = 0.12$.\newline
- If $P(X = 1) = 0.01$, then $P(X = 0) = 1 - P(X = 1) = 0.99.$\newline

Plug and chug:\newline
$$P(X = 1|Y = 1) = \dfrac {P(Y = 1|X = 1)P(X = 1)} {P(Y = 1|X = 1)P(X = 1) + P(Y = 1|X = 0) P(X = 0)},$$\newline
$$ = \dfrac {0.86 \times 0.01} {(0.86 \times 0.01) + (0.12 \times 0.99)},$$\newline
$$= 0.07.$$
```{r}
# calculations
(0.86 * 0.01) / ((0.86 * 0.01) + (0.12 * 0.99))
```

## (d)

**Answer:**\newline
```{r, echo=FALSE}
test <- matrix(c("0.8712","0.0014","0.1188","0.0086",0.99,0.01), ncol=3)
colnames(test) <- c('Negative', 'Positive', "Row Margin")
rownames(test) <- c('No Disease', 'Disease')
test.table <- as.table(test)
knitr::kable(test.table)
```

  
  Sensitivity (0.86) is the probability of a positive diagnosis given someone has the disease. That is, 86% of those with the disease will be identified with a positive test result. If 0.01 is the probability of having the disease, then 0.0086 is the probability of having the disease and receiving a positive diagnosis. That is, if I do not know whether or not I have the disease, there is a .0086 probability I will both receive a positive test result and truly have the disease. On the other hand, the specificity (0.88) gives us the probability of negative diagnosis with no disease - that is, if I know I do not have the disease, the test will identify me as negative 88% of the time. Therefore, if I know nothing about my disease, the probability that I will have no disease and receive a negative result is 0.8514. Most of the people with the disease are in the positive diagnosis column, which is a good thing. However, we can see based on the column margin that only about 7% of those who get a positive result actually have the disease. Needless stress!\newline


**Work:**\newline
We start with what we know:\newline
- $\textrm {Sensitivity} = \pi_1 = P(Y = 1|X = 1) = 0.86$.\newline
- $\textrm {Specificity} = 1 - \pi_2 = 1 - P(Y = 1|X = 0) = 0.88$\newline 
- $P(Y = 1|X = 0) = 0.12$.\newline
- $P(X = 0) = 0.99.$\newline
- $P(X = 1) = 0.01$
```{r, echo=FALSE}
test <- matrix(c("$\\pi_{00}$","$\\pi_{10}$","$\\pi_{01}$","$\\pi_{11}$",0.99,0.01), ncol=3)
colnames(test) <- c('Negative', 'Positive', "Row Margin")
rownames(test) <- c('No Disease', 'Disease')
test.table <- as.table(test)
knitr::kable(test.table)
```


Probability of both having disease and getting positive result:
```{r}
0.01 * 0.86
```

From there, because we have the margin and one of the cells, we have the other cell in that row:
```{r}
0.01 - 0.0086
```

Probability of negative diagnosis and not having disease: 
```{r}
0.99 * 0.88
```
Get the last cell:
```{r}
0.99 - 0.8712
```

```{r}
# check work
0.0086 + 0.0014
0.1386 + 0.8514
```


# 2.5

## (a)

**Answer:**\newline
Relative risk,though depending on the circumstances, one can sometimes use the odds ratio as an estimate of the relative risk; in those cases, it could be both. If the odds of either men or women getting cancer were small, the odds ratio and risk ratio would be pretty similar.\newline

## (b)

### (i)
**Answer:**\newline
0.55\newline

**Work:**\newline
The risk ratio is just % increase or decrease in risk, relative to 1.00 (1.00 would mean equal risk in both groups because 1.00 indicates that the numerator and denominator of the ratio are the same). If we know the drug group was 45% less likely to get cancer, then we consider what a 45% decrease from 1 would be: 0.55. Say we start with no effect:
$$RR = \dfrac {1} {1}.$$
But we know the drug group was 45% less likely to get cancer:
$$\dfrac {1 - 0.45} {1} = 0.55$$


### (ii)
**Answer:**\newline
1.82\newline

**Work:**\newline
We found the numerator for the risk ratio in part i. To get the RR for the placebo group, we flip the fraction from the last problem over:
```{r}
1 / (1 - 0.45)
```
So the placebo group wa 82% more likely to get cancer.


# 2.13

## (a)
**Answer:**\newline
(−0.018, 0.061). \newline


**Work:**\newline
 

Proportions: 
```{r}
# Proportion female who believed:
509 / 625
# Proportion male who believed:
398 / 502
```

Get the standard error:
$$SE = \sqrt {\dfrac {\hat \pi_1 (1 - \hat \pi_1)} {n_1} + \dfrac {\hat \pi_2 (1 - \hat \pi_2)} {n_2}},$$
$$= \sqrt {\dfrac {0.8144 (1 - 0.8144)} {625} + \dfrac {0.79 (1 - 0.79)} {502}},$$
```{r, chache = TRUE}
sqrt( (((0.8144 * (1-0.8144)) /625)) + ((0.7928287 * (1 - 0.7928287))  /502 )) 
```
Next, get the confidence interval:
$$(\hat \pi_1 - \hat \pi_2) \pm z_{0.1 /2} (SE), $$
$$(0.8144 - 0.7928) \pm 1.645 (0.0239),$$

$$= (-0.01764069, 0.06084069)$$ 
```{r}
# calculations
#lower
0.8144 - 0.7928 - 1.645 * 0.02385452
#upper
0.8144 - 0.7928 + 1.645 * 0.02385452
```

## (b)

**Answer:**\newline
CI for odds ratio: (0.8988938, 1.394697). However, odds ratios are very skewed, and because CIs are inferential statistics, we should probably use the log odds instead. If using the log of the odds, the CI is (-0.1109301, 0.3848729). Interpretation is that if we were to collect 100 samples of this size from this same population, 90 out of 100 of the calculated CIs for the odds (or log odds) ratios will encapsulate the true population parameter, while 10 will fail to do so just due to sampling variability. We of course are counting on our sample having not been one of those 10% of samples that will fail to capture the population parameter due to sampling variability. 

**Work:**\newline

Use the standard error formula
$$SE = \sqrt {(\dfrac {1} {n_{00} }) + (\dfrac {1} {n_{01} }) + (\dfrac {1} {n_{10} }) + (\dfrac {1} {n_{11} }) } ,$$
and the CI for log odds:
$$\textrm {log} \hat \theta ± z_{0.1/2} (SE).$$
```{r, cache = TRUE}
# calculate standard error
sqrt((1/509) + (1/398) + (1/116) + (1/104) )
# get log odds
(OddsRatio <- (0.8144 / (1 - 0.8144)) / (0.7928 / (1 - 0.7928)))
# CI lower
OddsRatio - 1.645 * 0.1507
# CI upper
OddsRatio + 1.645 * 0.1507
# what about for log odds?
logodds <- log(OddsRatio)
# CI lower - log
logodds - 1.645 * 0.1507
# CI upper - log
logodds + 1.645 * 0.1507
```

## (c)

**Answer:**\newline
$\chi^2 = 0.825, df =1, p = 0.36$\newline


**Work:**\newline


Conduct a test of statistical independence. Report the P -value and interpret.

X 2 = 0.8, df = 1, P-value = 0.36.

```{r, cache = FALSE, echo=FALSE}
# make a contigency table
belief <- matrix(c("509","398",(509 + 398),"116","104",(116 + 104), (509 + 116),(398 + 104), (907 + 220)), ncol=3)
colnames(belief) <- c('Belief', 'Disbelief', "Row Margin")
rownames(belief) <- c('Female', 'Male', "Column Margin")
belief.table <- as.table(belief)
knitr::kable(belief.table, format = "markdown")
```
$n_{00}$
```{r}
(502 * 220) / 1127
```
$n_{01}$
```{r}
(502 * 907) / 1127
```
$n_{10}$
```{r}
(625 * 220) / 1127
```
$n_{11}$
```{r}
(625 * 907) / 1127
```

Following the chi-square formula:
$$\chi^2  = \sum \dfrac {(n_{ij} - \hat \mu_{ij})^2} {\hat \mu_{ij}}$$
```{r}
cell_00 <- (104 - 97.99468)^2 / 97.99468
cell_01 <- (398 - 404.0053)^2 / 404.0053
cell_10 <- (116 - 122.0053)^2 / 122.0053
cell_11 <- (509 - 502.9947)^2 / 502.9947
cell_00 + cell_01 + cell_10 + cell_11
```


```{r}
# check work, get p-value
belief_test <- matrix(c(509,398,116,104), ncol=2)
colnames(belief_test) <- c('Belief', 'Disbelief')
rownames(belief_test) <- c('Female', 'Male')
belief_test <- as.table(belief_test)
knitr::kable(belief_test, format = "markdown")
chisq.test(belief_test, correct = FALSE)
```

# 2.21

## (a)

**Answer:**\newline
No, there are redundances in each of the column. With $\chi^2$, you want to know if two constructs are independent, or if they are not independent, then it is because of some association between the constructs themselves. With this table,  dependence might be due to associations between the constructs, but could also be due to subjects being double- or triple-counted across cells. You can't really tell unless the observations in the cells are dependent.


## (b)

**Answer:**\newline
Yes, if there were 100 subjects of each gender, then the numbers in the cells are out of 100. 

```{r}
# check work, get p-value
install.packages("data.table")
library(data.table)
gender <- matrix(c(60,40,75,25), ncol=1)
colnames(gender) <- c('Gender')
rownames(gender) <- c('mYes', 'mNo', 'Yes', 'No')
gender <- cro(gender)

gender
```

