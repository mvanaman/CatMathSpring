---
title: "CatData HW3"
author: "Matthew Vanaman"
date: "03/11/19"
monofont: Courier New
output:
  word_document: default
  pdf_document:
    latex_engine: xelatex
header-includes: \usepackage{tikz,xcolor,listings}
---
`r knitr::opts_knit$set(root.dir='..')`

```{r, include=FALSE, cache=TRUE}
library(ProjectTemplate); load.project()
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
options(scipen = 999)
```

A2.5, A2.13, A2.21, A2.36. (3 points each)

A2.33 (5 points)

*All code and work are shown in the appendix.*

# 2.2

## (a)
**Answer:**\newline
Recoding this in a way that makes more sense to me. Will leave X and Y as they are:\newline

- $X (0 = \textrm {no disease}, 1 = \textrm {disease})$\newline
- $Y (0 = \textrm {negative}, 1 = \textrm {positive})$\newline
- $\textrm {Sensitivity} = \pi_1 = P(Y = 1|X = 1) = \textrm {probability positive diagnosis given disease}$\newline
- $\textrm {Specificity} = 1 - \pi_2 = 1 - P(Y = 1|X = 0) = \textrm {1 - probability positive diagnosis given no disease}$\newline 

After subtracting away the  probability of positive diagnosis given no disease, you are left with probability of negative diagnosis given no disease:\newline

$1 - P(Y = 1|X = 0) =  P(Y = 0|X = 0) = \textrm {probability negative diagnosis given no disease}$\newline

Likewise, the "noise" of the test is captured by 1 - specificity. A good test would want to show that 1 - specificity yields a large probability as an effective test will have a large probability of correctly screening patients that do not have the disease. \newline

## (b)
**Answer:**\newline
$P(X = 1|Y = 1) = \dfrac {P(Y = 1|X = 1)P(X = 1)} {P(Y = 1|X = 1)P(X = 1) + P(Y = 1|X = 0) P(X = 0)}$.\newline



**Work:**\newline
$$\dfrac {\pi_1 \gamma} {[ \pi_1 \gamma + \pi_2 (1 - \gamma) ]} = \dfrac {P(B|A)P(A)} {P(B)} = \textrm {Bayes' rule}$$.\newline

In the above equation, P(B) represents P(X=1), or the probability of having the disease. But this is an unknown value expressed as $\gamma$, we have to use a particular version of Bayes' rule that takes into account the conditional probabilities associated with P(B):\newline
$$P(A|B) = \dfrac {P(B|A)P(A)} {P(B|A)P(A) + P(B| \widetilde A) P(\widetilde A)}.$$\newline
Just replace with the problem's notation:
$$P(X = 1|Y = 1) = \dfrac {P(Y = 1|X = 1)P(X = 1)} {P(Y = 1|X = 1)P(X = 1) + P(Y = 1|X = 0) P(X = 0)}$$.\newline

## (c)
**Answer:**\newline
0.07\newline


**Work:**\newline

We need to solve for $P(X = 1 | Y = 1)$. Lay out the pieces:\newline

- $X (0 = \textrm {no disease}, 1 = \textrm {disease}$.\newline
- $P(X = 1) = 0.01$.\newline
- $Y (0 = \textrm {negative}, 1 = \textrm {positive}$.\newline
- $\textrm {Sensitivity} = \pi_1 = P(Y = 1|X = 1) = 0.86$.\newline
- $\textrm {Specificity} = 1 - \pi_2 = 1 - P(Y = 1|X = 0) = 0.88$\newline 
- If $1 - P(Y = 1|X = 0) = 0.88$, then $P(Y = 1|X = 0) = 0.12$.\newline
- If $P(X = 1) = 0.01$, then $P(X = 0) = 1 - P(X = 1) = 0.99.$\newline

Plug and chug:\newline
$$P(X = 1|Y = 1) = \dfrac {P(Y = 1|X = 1)P(X = 1)} {P(Y = 1|X = 1)P(X = 1) + P(Y = 1|X = 0) P(X = 0)},$$\newline
$$ = \dfrac {0.86 \times 0.01} {(0.86 \times 0.01) + (0.12 \times 0.99)},$$\newline
$$= 0.07.$$
```{r, cache=TRUE}
# calculations
(0.86 * 0.01) / ((0.86 * 0.01) + (0.12 * 0.99))
```

## (d)

**Answer:**\newline
```{r, cache=TRUE, echo=FALSE}
test <- matrix(c("0.8712","0.0014","0.1188","0.0086",0.99,0.01), ncol=3)
colnames(test) <- c('Negative', 'Positive', "Row Margin")
rownames(test) <- c('No Disease', 'Disease')
test.table <- as.table(test)
knitr::kable(test.table)
```

  
  Sensitivity (0.86) is the probability of a positive diagnosis given someone has the disease. That is, 86% of those with the disease will be identified with a positive test result. If 0.01 is the probability of having the disease, then 0.0086 is the probability of having the disease and receiving a positive diagnosis. That is, if I do not know whether or not I have the disease, there is a .0086 probability I will both receive a positive test result and truly have the disease. On the other hand, the specificity (0.88) gives us the probability of negative diagnosis with no disease - that is, if I know I do not have the disease, the test will identify me as negative 88% of the time. Therefore, if I know nothing about my disease, the probability that I will have no disease and receive a negative result is 0.8514. Most of the people with the disease are in the positive diagnosis column, which is a good thing. However, we can see based on the column margin that only about 7% of those who get a positive result actually have the disease. Needless stress!\newline


**Work:**\newline
We start with what we know:\newline
- $\textrm {Sensitivity} = \pi_1 = P(Y = 1|X = 1) = 0.86$.\newline
- $\textrm {Specificity} = 1 - \pi_2 = 1 - P(Y = 1|X = 0) = 0.88$\newline 
- $P(Y = 1|X = 0) = 0.12$.\newline
- $P(X = 0) = 0.99.$\newline
- $P(X = 1) = 0.01$
```{r, echo=FALSE, cache=TRUE}
test <- matrix(c("$\\pi_{00}$","$\\pi_{10}$","$\\pi_{01}$","$\\pi_{11}$",0.99,0.01), ncol=3)
colnames(test) <- c('Negative', 'Positive', "Row Margin")
rownames(test) <- c('No Disease', 'Disease')
test.table <- as.table(test)
knitr::kable(test.table)
```


Probability of both having disease and getting positive result:
```{r, cache=TRUE}
0.01 * 0.86
```

From there, because we have the margin and one of the cells, we have the other cell in that row:
```{r, cache=TRUE}
0.01 - 0.0086
```

Probability of negative diagnosis and not having disease: 
```{r, cache=TRUE}
0.99 * 0.88
```
Get the last cell:
```{r, cache=TRUE}
0.99 - 0.8712
```

```{r, cache=TRUE}
# check work
0.0086 + 0.0014
0.1386 + 0.8514
```


# 2.5

## (a)

**Answer:**\newline
Relative risk,though depending on the circumstances, one can sometimes use the odds ratio as an estimate of the relative risk; in those cases, it could be both. If the odds of either men or women getting cancer were small, the odds ratio and risk ratio would be pretty similar.\newline

## (b)

### (i)
**Answer:**\newline
0.55\newline

**Work:**\newline
The risk ratio is just % increase or decrease in risk, relative to 1.00 (1.00 would mean equal risk in both groups because 1.00 indicates that the numerator and denominator of the ratio are the same). If we know the drug group was 45% less likely to get cancer, then we consider what a 45% decrease from 1 would be: 0.55. Say we start with no effect:
$$RR = \dfrac {1} {1}.$$
But we know the drug group was 45% less likely to get cancer:
$$\dfrac {1 - 0.45} {1} = 0.55$$


### (ii)
**Answer:**\newline
1.82\newline

**Work:**\newline
We found the numerator for the risk ratio in part i. To get the RR for the placebo group, we flip the fraction from the last problem over:
```{r, cache=TRUE}
1 / (1 - 0.45)
```
So the placebo group wa 82% more likely to get cancer.
